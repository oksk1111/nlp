{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPQJORuZxl/e7x/eK/N7Z5X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 정수 인코딩\n","\n","각 단어에 해당하는 고유한 맵핑 id가 있어야만 단어 구분이 가능하다.<br>\n","해당 정수 인코딩 값은 추후 원핫인코딩 이후 벡터임베딩에 활용된다.<br>\n","벡터임베딩 이후 단어간의 거리를 이용한 유사도 측정까지도 고려할 수 있게 된다."],"metadata":{"id":"Ss73Bw2zwpnY"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvjnbHBIwPg_","executionInfo":{"status":"ok","timestamp":1735278386152,"user_tz":-540,"elapsed":10719,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"f726b700-3cc4-449c-9f55-e3c437c47ddb"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}],"source":["from nltk.tokenize import sent_tokenize\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","\n","import nltk\n","nltk.download(\"punkt_tab\")\n","nltk.download(\"stopwords\")"]},{"cell_type":"code","source":["# sample document\n","raw_text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\"\n"],"metadata":{"id":"_DM27zsBxUmT","executionInfo":{"status":"ok","timestamp":1735278402447,"user_tz":-540,"elapsed":516,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# 문장 토큰화\n","sentences = sent_tokenize(raw_text)\n","print(sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KZtXsN6jxukV","executionInfo":{"status":"ok","timestamp":1735278402945,"user_tz":-540,"elapsed":9,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"dc077bd7-96e8-48d0-da36-a5bac73f82c7"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["['A barber is a person.', 'a barber is good person.', 'a barber is huge person.', 'he Knew A Secret!', 'The Secret He Kept is huge secret.', 'Huge secret.', 'His barber kept his word.', 'a barber kept his word.', 'His barber kept his secret.', 'But keeping and keeping such a huge secret to himself was driving the barber crazy.', 'the barber went up a huge mountain.']\n"]}]},{"cell_type":"code","source":["# 단어 토큰화; 정제 + 정규화\n","#- 소문자화\n","#- 불용어 처리\n","\n","vocab = {}\n","preprocessed_sentences = []\n","stop_words = set(stopwords.words(\"english\"))\n","\n","for sentence in sentences:\n","    # 단어 토큰화\n","    tokenized_sentence = word_tokenize(sentence)\n","    result = []\n","\n","    for word in tokenized_sentence:\n","        word = word.lower() # 소문자화\n","        if word not in stop_words: # 불용어 처리\n","            if len(word) > 2: # 단어 길이가 2 이하는 제거\n","                result.append(word)\n","                if word not in vocab: # 단어의 노출 빈도 확인\n","                    vocab[word] = 0\n","                vocab[word] += 1\n","    preprocessed_sentences.append(result)\n","print(preprocessed_sentences)\n","print(vocab) # 단어 빈도\n","print(vocab[\"barber\"]) # 특정 단어의 빈도"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lOd4k74fx2lW","executionInfo":{"status":"ok","timestamp":1735278403992,"user_tz":-540,"elapsed":4,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"6765c779-060e-4ff8-bb03-0b159ac37568"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n","{'barber': 8, 'person': 3, 'good': 1, 'huge': 5, 'knew': 1, 'secret': 6, 'kept': 4, 'word': 2, 'keeping': 2, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1}\n","8\n"]}]},{"cell_type":"code","source":["# 빈도가 높은 단어에 우선순위를 위한 낮은 정수 부여\n","vocab_sorted = sorted(vocab.items(), key=lambda x:x[1], reverse=True)\n","print(vocab_sorted)\n","\n","# 빈도수가 작은 단어는 제외\n","word_to_index = {}\n","i = 0\n","for (word, frequency) in vocab_sorted:\n","    if frequency > 1:\n","        i = i + 1\n","        word_to_index[word] = i\n","print(word_to_index)\n","\n","# 인덱스가 5 초과인 단어 제거 (= 빈도 낮은 단어)\n","vocab_size = 5\n","words_frequency = [word for word, index in word_to_index.items() if index >= vocab_size + 1]\n","for w in words_frequency:\n","    del word_to_index[w] # 해당 단어에 대한 인덱스 정보를 삭제\n","print(word_to_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kwp5eq6Y1F2e","executionInfo":{"status":"ok","timestamp":1735278405413,"user_tz":-540,"elapsed":6,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"2de46bfb-dadb-413e-c99b-b9c553aaf47b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2), ('good', 1), ('knew', 1), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)]\n","{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7}\n","{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"]}]},{"cell_type":"code","source":["# 단어집합에 존재하지 않는 단어를 추가\n","#- Out Of Vocabulary (OOV)\n","word_to_index['OOV'] = len(word_to_index) + 1\n","print(word_to_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y78QnEL76Ket","executionInfo":{"status":"ok","timestamp":1735278407060,"user_tz":-540,"elapsed":7,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"06531b0a-6f06-422b-9a2b-53c22072682f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'OOV': 6}\n"]}]},{"cell_type":"code","source":["# 정수 인코딩\n","encoded_sentences = []\n","for sentence in preprocessed_sentences:\n","    encoded_sentence = []\n","    for word in sentence:\n","        try:\n","            # 단어 집합에 있는 단어라면 해당 단어의 정수를 리턴\n","            encoded_sentence.append(word_to_index[word])\n","        except:\n","            # 단어 집합에 없는 단어라면 'OOV'의 정수를 리턴\n","            encoded_sentence.append(word_to_index['OOV'])\n","    encoded_sentences.append(encoded_sentence)\n","print(encoded_sentences)\n","print(preprocessed_sentences) # 어떤 단어와 매칭되는지 확인"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vi_-cHzfAB20","executionInfo":{"status":"ok","timestamp":1735278408693,"user_tz":-540,"elapsed":7,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"08763310-6170-4ab5-a848-7e21353128c3"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1, 5], [1, 6, 5], [1, 3, 5], [6, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [6, 6, 3, 2, 6, 1, 6], [1, 6, 3, 6]]\n","[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"]}]},{"cell_type":"markdown","source":["위 실습은 이해를 위한 정수 인코딩 방법을 진행한 것일 뿐이며, 실제는 Counter, FreqDist, enumerate, 케라스 토크나이저 등을 사용하자."],"metadata":{"id":"2fthgMqLBthJ"}},{"cell_type":"markdown","source":["# Counter 사용하기"],"metadata":{"id":"De6ZEIzdCmSA"}},{"cell_type":"code","source":["# 하나의 단어 집합을 만들기\n","\n","from collections import Counter\n","print(preprocessed_sentences)\n","\n","all_words_list = sum(preprocessed_sentences, []) #== words = np.hstack(preprocessed_sentences)\n","print(all_words_list)\n","\n","# 파이썬 Counter로 단어 빈도수 카운트\n","vocab = Counter(all_words_list)\n","print(vocab)\n","print(vocab[\"barber\"]) # 특정 단어의 빈도수"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x7luNDshBMvb","executionInfo":{"status":"ok","timestamp":1735278556103,"user_tz":-540,"elapsed":496,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"d44e3038-e470-49b7-d71b-6310ffd9d32c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n","['barber', 'person', 'barber', 'good', 'person', 'barber', 'huge', 'person', 'knew', 'secret', 'secret', 'kept', 'huge', 'secret', 'huge', 'secret', 'barber', 'kept', 'word', 'barber', 'kept', 'word', 'barber', 'kept', 'secret', 'keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy', 'barber', 'went', 'huge', 'mountain']\n","Counter({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1})\n","8\n"]}]},{"cell_type":"code","source":["# 빈도수가 높은 것만 남기기\n","vocab_size = 5\n","vocab = vocab.most_common(vocab_size)\n","print(vocab)"],"metadata":{"id":"yDHTCj4xDsFi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735278877379,"user_tz":-540,"elapsed":529,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"1ed124bd-77d5-4960-b228-c1911e12e0e7"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]\n"]}]},{"cell_type":"code","source":["# 빈도수 높은 순으로 index 부여\n","word_to_index = {}\n","i = 0\n","for (word, frequency) in vocab:\n","    i = i + 1\n","    word_to_index[word] = i\n","\n","print(word_to_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HIBvvUhKrexj","executionInfo":{"status":"ok","timestamp":1735278967702,"user_tz":-540,"elapsed":717,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"5d8a5cd3-4954-4b9e-94bd-6b0901fe8a09"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"]}]},{"cell_type":"markdown","source":["# NLTK의 FreqDist 사용하기"],"metadata":{"id":"a4Yu6jyBr9M1"}},{"cell_type":"code","source":["from nltk import FreqDist\n","import numpy as np"],"metadata":{"id":"xO1Ee68Vr7Me","executionInfo":{"status":"ok","timestamp":1735279010957,"user_tz":-540,"elapsed":651,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["vocab = FreqDist(np.hstack(preprocessed_sentences))\n","print(vocab)\n","print(vocab[\"barber\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"njPcFStgsF00","executionInfo":{"status":"ok","timestamp":1735279069395,"user_tz":-540,"elapsed":9,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"27ec44d2-fa59-4c7e-8763-d074d776e72c"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["<FreqDist with 13 samples and 36 outcomes>\n","8\n"]}]},{"cell_type":"code","source":["# 빈도수 높은 것만 남기기\n","vocab_size = 5\n","vocab = vocab.most_common(vocab_size)\n","print(vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CbujUUoesTv4","executionInfo":{"status":"ok","timestamp":1735279154791,"user_tz":-540,"elapsed":538,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"0e201c6e-b1e9-411e-8c8a-d985f1db6ea0"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]\n"]}]},{"cell_type":"code","source":["# 빈도수 높은 순으로 index 부여\n","word_to_index = {word[0] : index + 1 for index, word in enumerate(vocab)}\n","print(word_to_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MFJ1o71TspCX","executionInfo":{"status":"ok","timestamp":1735279220225,"user_tz":-540,"elapsed":618,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"2d19c646-0d05-411e-cf8a-ab1c92fefdd7"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"]}]},{"cell_type":"markdown","source":["# 케라스(Keras)의 텍스트 전처리"],"metadata":{"id":"hcezXHbftJ5K"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer"],"metadata":{"id":"GmGOLlC7s4yO","executionInfo":{"status":"ok","timestamp":1735279350983,"user_tz":-540,"elapsed":470,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["tokenizer = Tokenizer()\n","\n","# fit_on_texts()안에 코퍼스를 입력으로 하면 빈도수를 기준으로 단어 집합을 생성\n","tokenizer.fit_on_texts(preprocessed_sentences)\n","print(tokenizer.word_index)\n","print(tokenizer.word_counts)\n","print(tokenizer.texts_to_sequences(preprocessed_sentences))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GV-fa33JtZA8","executionInfo":{"status":"ok","timestamp":1735279576268,"user_tz":-540,"elapsed":515,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"d1b7e5b8-db84-4a29-a00b-ece8fbda1b91"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n","OrderedDict([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n","[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"]}]},{"cell_type":"code","source":["# 빈도수 높은 것만 남기기\n","vocab_size = 5\n","tokenizer = Tokenizer(num_words=vocab_size+1)\n","tokenizer.fit_on_texts(preprocessed_sentences) # 단어 빈도수가 높은 순으로 낮은 정수 인덱스를 부여\n","print(tokenizer.word_index) # 적용 안됨\n","print(tokenizer.word_counts) # 적용 안됨\n","print(tokenizer.texts_to_sequences(preprocessed_sentences)) # 적용됨"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vPUowcyWtetZ","executionInfo":{"status":"ok","timestamp":1735279807490,"user_tz":-540,"elapsed":506,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"c04e3917-d50e-4bfb-cac5-f96b26976480"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n","OrderedDict([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n","[[1, 5], [1, 5], [1, 3, 5], [2], [2, 4, 3, 2], [3, 2], [1, 4], [1, 4], [1, 4, 2], [3, 2, 1], [1, 3]]\n"]}]},{"cell_type":"code","source":["# 위 코드의 다른 방법 (적용 안된 사항을 적용하는 방법. 잘 사용 안함)\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(preprocessed_sentences)\n","\n","vocab_size = 5\n","words_frequency = [word for word, index in tokenizer.word_index.items() if index >= vocab_size + 1]\n","for w in words_frequency:\n","    del tokenizer.word_index[w] # 해당 단어에 대한 인덱스 정보를 삭제\n","    del tokenizer.word_counts[w] # 해당 단어에 대한 카운트 정보를 삭제\n","\n","print(tokenizer.word_index)\n","print(tokenizer.word_counts)\n","print(tokenizer.texts_to_sequences(preprocessed_sentences))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YsPlYRthuvw5","executionInfo":{"status":"ok","timestamp":1735280009521,"user_tz":-540,"elapsed":510,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"9eeaf4f2-6452-4e02-da50-4e4139487760"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n","OrderedDict([('barber', 8), ('person', 3), ('huge', 5), ('secret', 6), ('kept', 4)])\n","[[1, 5], [1, 5], [1, 3, 5], [2], [2, 4, 3, 2], [3, 2], [1, 4], [1, 4], [1, 4, 2], [3, 2, 1], [1, 3]]\n"]}]},{"cell_type":"code","source":["# 숫자 0과 OOV를 고려해서 단어 집합의 크기는 +2\n","vocab_size = 5\n","tokenizer = Tokenizer(num_words=vocab_size+2, oov_token='OOV')\n","tokenizer.fit_on_texts(preprocessed_sentences)\n","print('index of OOV:', tokenizer.word_index['OOV'])\n","print(tokenizer.texts_to_sequences(preprocessed_sentences))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tU4cImw3v23M","executionInfo":{"status":"ok","timestamp":1735280146034,"user_tz":-540,"elapsed":519,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"fbb98653-4fd7-4a7e-a355-66a8f4170ec9"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["index of OOV: 1\n","[[2, 6], [2, 1, 6], [2, 4, 6], [1, 3], [3, 5, 4, 3], [4, 3], [2, 5, 1], [2, 5, 1], [2, 5, 3], [1, 1, 4, 3, 1, 2, 1], [2, 1, 4, 1]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"13pJskGXwa3t"},"execution_count":null,"outputs":[]}]}