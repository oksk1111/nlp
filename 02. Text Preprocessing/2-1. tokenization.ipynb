{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPHLT2WEQ9JeSb2UsPzjf0a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Tokenization\n","\n","주어진 텍스트입력을 토큰단위로 나누는 행위<br>\n","\n","nltk: 영어 코퍼스를 토큰화하기 위한 도구를 제공\n"],"metadata":{"id":"ZqYEU7AroJdH"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M1BxHHvenIev","executionInfo":{"status":"ok","timestamp":1735177403071,"user_tz":-540,"elapsed":207695,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"3428c38a-629e-4286-9af8-2fc8cb82a2b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n","Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.5.1)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (5.3.0)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n","Collecting kss\n","  Downloading kss-6.0.4.tar.gz (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting emoji==1.2.0 (from kss)\n","  Downloading emoji-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n","Collecting pecab (from kss)\n","  Downloading pecab-1.0.8.tar.gz (26.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from kss) (3.4.2)\n","Collecting jamo (from kss)\n","  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n","Collecting hangul-jamo (from kss)\n","  Downloading hangul_jamo-1.0.1-py3-none-any.whl.metadata (899 bytes)\n","Collecting tossi (from kss)\n","  Downloading tossi-0.3.1.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting distance (from kss)\n","  Downloading Distance-0.1.3.tar.gz (180 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pyyaml==6.0 (from kss)\n","  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.0 kB)\n","Collecting unidecode (from kss)\n","  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n","Collecting cmudict (from kss)\n","  Downloading cmudict-1.0.32-py3-none-any.whl.metadata (3.6 kB)\n","Collecting koparadigm (from kss)\n","  Downloading koparadigm-0.10.0-py3-none-any.whl.metadata (2.9 kB)\n","Collecting kollocate (from kss)\n","  Downloading kollocate-0.0.2-py3-none-any.whl.metadata (1.8 kB)\n","Collecting bs4 (from kss)\n","  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from kss) (1.26.4)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from kss) (8.3.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from kss) (1.13.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->kss) (4.12.3)\n","Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.10/dist-packages (from cmudict->kss) (8.5.0)\n","Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.10/dist-packages (from cmudict->kss) (6.4.5)\n","Collecting whoosh (from kollocate->kss)\n","  Downloading Whoosh-2.7.4-py2.py3-none-any.whl.metadata (3.1 kB)\n","Collecting xlrd==1.2.0 (from koparadigm->kss)\n","  Downloading xlrd-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (17.0.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (2024.11.6)\n","Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->kss) (1.2.2)\n","Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->kss) (2.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->kss) (24.2)\n","Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest->kss) (1.5.0)\n","Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest->kss) (2.2.1)\n","Collecting bidict (from tossi->kss)\n","  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tossi->kss) (1.17.0)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=5->cmudict->kss) (3.21.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->kss) (2.6)\n","Downloading emoji-1.2.0-py3-none-any.whl (131 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.3/131.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n","Downloading cmudict-1.0.32-py3-none-any.whl (939 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.4/939.4 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hangul_jamo-1.0.1-py3-none-any.whl (4.4 kB)\n","Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n","Downloading kollocate-0.0.2-py3-none-any.whl (72.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.2/72.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading koparadigm-0.10.0-py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bidict-0.23.1-py3-none-any.whl (32 kB)\n","Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: kss, distance, pecab, tossi\n","  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kss: filename=kss-6.0.4-cp310-cp310-linux_x86_64.whl size=1446488 sha256=18b9a2a4ba6b5cbfc326f0e945bf8a9bd29e6d14466b3657887a8a36dde645ec\n","  Stored in directory: /root/.cache/pip/wheels/dd/70/d5/c9308346829b1eb9e7267d74696919d2453aee6ce350f98b3b\n","  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16256 sha256=7e13d5cdf484f36a82a19146d3720600f500189b44eb3ca490a1d67324559b42\n","  Stored in directory: /root/.cache/pip/wheels/e8/bb/de/f71bf63559ea9a921059a5405806f7ff6ed612a9231c4a9309\n","  Building wheel for pecab (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pecab: filename=pecab-1.0.8-py3-none-any.whl size=26646665 sha256=27338200453d0d310111028864ae4d39f0d463d2d24e2074999b4a286d9106c4\n","  Stored in directory: /root/.cache/pip/wheels/5c/6f/b4/ab61b8863d7d8b1409def8ae31adcaa089fa91b8d022ec309d\n","  Building wheel for tossi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tossi: filename=tossi-0.3.1-py3-none-any.whl size=12130 sha256=9b45c17bb43b68f2da7d9c153886835b829fd6278686401129597f6f228b0470\n","  Stored in directory: /root/.cache/pip/wheels/a7/18/60/1094a6fe93c8063efcd3e6700d09328216682e495a3c51af9f\n","Successfully built kss distance pecab tossi\n","Installing collected packages: whoosh, jamo, hangul-jamo, emoji, distance, xlrd, unidecode, pyyaml, kollocate, bidict, tossi, pecab, koparadigm, cmudict, bs4, kss\n","  Attempting uninstall: xlrd\n","    Found existing installation: xlrd 2.0.1\n","    Uninstalling xlrd-2.0.1:\n","      Successfully uninstalled xlrd-2.0.1\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 6.0.2\n","    Uninstalling PyYAML-6.0.2:\n","      Successfully uninstalled PyYAML-6.0.2\n","Successfully installed bidict-0.23.1 bs4-0.0.2 cmudict-1.0.32 distance-0.1.3 emoji-1.2.0 hangul-jamo-1.0.1 jamo-0.4.1 kollocate-0.0.2 koparadigm-0.10.0 kss-6.0.4 pecab-1.0.8 pyyaml-6.0 tossi-0.3.1 unidecode-1.3.8 whoosh-2.7.4 xlrd-1.2.0\n"]}],"source":["!pip install konlpy\n","!pip install kss"]},{"cell_type":"code","source":["import nltk\n","#nltk.download('punkt')\n","nltk.download('punkt_tab')\n","nltk.download('averaged_perceptron_tagger')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vB9z2bYtnjsR","executionInfo":{"status":"ok","timestamp":1735178293379,"user_tz":-540,"elapsed":567,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"322170db-27a3-4c31-b277-72f6b200b04e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["# 단어 토큰화 (Word Tokenization)\n","\n","토큰의 단위를 단어로 하는 경우. 토큰은 꼭 단어일 필요는 없다."],"metadata":{"id":"fbT7soTEqAOe"}},{"cell_type":"code","source":["from nltk.tokenize import word_tokenize\n","from nltk.tokenize import WordPunctTokenizer\n","from tensorflow.keras.preprocessing.text import text_to_word_sequence"],"metadata":{"id":"rv1ynatep89w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 여러 토큰화 기법 사용 예\n","sample = \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"\n","print('tokenization1:', word_tokenize(sample))\n","print('tokenization2:', WordPunctTokenizer().tokenize(sample))\n","print('tokenization3:', text_to_word_sequence(sample))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dkOERbfjqnyh","executionInfo":{"status":"ok","timestamp":1735178302398,"user_tz":-540,"elapsed":327,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"02d6b78a-6741-4163-fe96-968ad9bf137a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tokenization1: ['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n","tokenization2: ['Don', \"'\", 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr', '.', 'Jone', \"'\", 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n","tokenization3: [\"don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'mr', \"jone's\", 'orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"]}]},{"cell_type":"markdown","source":["# 토큰화 시 고려사항\n","\n","구두점이나 특수 문자를 단순 제외해서는 안 된다. <br>\n","줄임말과 단어 내에 띄어쓰기가 있는 경우 <br><br>\n","\n","아래 예시는 다음 규칙으로 tokenize를 수행<br>\n","- 규칙 1. 하이푼으로 구성된 단어는 하나로 유지한다.\n","- 규칙 2. doesn't와 같이 아포스트로피로 '접어'가 함께하는 단어는 분리해준다."],"metadata":{"id":"7D9DhKGpscFu"}},{"cell_type":"code","source":["from nltk.tokenize import TreebankWordTokenizer\n","\n","tokenizer = TreebankWordTokenizer()\n","\n","text = \"Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own.\"\n","print(tokenizer.tokenize(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gqfRZY8FrKzA","executionInfo":{"status":"ok","timestamp":1735179553384,"user_tz":-540,"elapsed":288,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"072bc4fc-1114-4e23-82b4-bfeff7f20bdd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Starting', 'a', 'home-based', 'restaurant', 'may', 'be', 'an', 'ideal.', 'it', 'does', \"n't\", 'have', 'a', 'food', 'chain', 'or', 'restaurant', 'of', 'their', 'own', '.']\n"]}]},{"cell_type":"markdown","source":["# 문장 토큰화 (Sentence Tokenization)\n","\n","보통 갖고있는 코퍼스가 정제되지 않은 상태라면, 코퍼스는 문장 단위로 구분되어 있지 않아서 이를 사용하고자 하는 용도에 맞게 문장 토큰화가 필요할 수 있다."],"metadata":{"id":"hCR2CfUWxZsB"}},{"cell_type":"code","source":["from nltk.tokenize import sent_tokenize\n","\n","#tokenizer = sent_tokenize()\n","\n","text1 = \"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\"\n","print(sent_tokenize(text1))\n","\n","text2 = \"I am actively looking for Ph.D. students. and you are a Ph.D student.\" # '.' 이 있어도 문장단위로 잘라냄을 확인\n","print(sent_tokenize(text2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A8PnLIPcwseV","executionInfo":{"status":"ok","timestamp":1735180040836,"user_tz":-540,"elapsed":382,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"d9a5eadb-1ede-45bc-a8ce-2e1d98c0066f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['His barber kept his word.', 'But keeping such a huge secret to himself was driving him crazy.', 'Finally, the barber went up a mountain and almost to the edge of a cliff.', 'He dug a hole in the midst of some reeds.', 'He looked about, to make sure no one was near.']\n","['I am actively looking for Ph.D. students.', 'and you are a Ph.D student.']\n"]}]},{"cell_type":"code","source":["import kss\n","\n","text = '딥 러닝 자연어 처리가 재미있기는 합니다. 그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다. 이제 해보면 알걸요?'\n","print(kss.split_sentences(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WQeowRxBx2g7","executionInfo":{"status":"ok","timestamp":1735180139285,"user_tz":-540,"elapsed":12590,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"29dd780a-7f7e-4abc-ce42-601a9e277548"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:Oh! You have mecab in your environment. Kss will take this as a backend! :D\n","\n"]},{"output_type":"stream","name":"stdout","text":["['딥 러닝 자연어 처리가 재미있기는 합니다.', '그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다.', '이제 해보면 알걸요?']\n"]}]},{"cell_type":"markdown","source":["# NLTK와 KoNLPy를 이용한 영어, 한국어 토큰화\n","\n","## 한국어 토큰화의 어려움\n","한국어는 교착어. 교착어란 조사, 어미 등을 붙여서 말을 만드는 언어<br>\n","이런 언어는 토큰을 가장 작은 말의 안뒤인 형태소 단위로 나누어야 한다.\n","- 자립형태소: 접사, 어미, 조사와 상관없이 자립하여 사용할 수 있는 형태소. 그 자체로 단어가 된다. 체언(명사, 대명사, 수사), 수식언(관형사, 부사), 감탄사 등이 있다.\n","- 의존형태소: 다른 형태소와 결합하여 사용되는 형태소. 접사, 어미, 조사, 어간을 말한다."],"metadata":{"id":"55TYlcJHzDyw"}},{"cell_type":"code","source":["from nltk.tokenize import word_tokenize\n","from nltk.tag import pos_tag\n","nltk.download('averaged_perceptron_tagger_eng')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IGL5xEBGy4hH","executionInfo":{"status":"ok","timestamp":1735180470159,"user_tz":-540,"elapsed":267,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"1a4fac9f-0bd3-4b0a-ecb3-f61df287b107"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["# 영어 POS\n","text = \"I am actively looking for Ph.D. students. and you are a Ph.D. student.\"\n","tokenized_sentence = word_tokenize(text)\n","\n","print('work tokenize:', tokenized_sentence)\n","print('pos tag:', pos_tag(tokenized_sentence))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"csz3cLvvzXtn","executionInfo":{"status":"ok","timestamp":1735180472972,"user_tz":-540,"elapsed":275,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"43f9695f-64fc-4b25-ed4e-5a00701558d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["work tokenize: ['I', 'am', 'actively', 'looking', 'for', 'Ph.D.', 'students', '.', 'and', 'you', 'are', 'a', 'Ph.D.', 'student', '.']\n","pos tag: [('I', 'PRP'), ('am', 'VBP'), ('actively', 'RB'), ('looking', 'VBG'), ('for', 'IN'), ('Ph.D.', 'NNP'), ('students', 'NNS'), ('.', '.'), ('and', 'CC'), ('you', 'PRP'), ('are', 'VBP'), ('a', 'DT'), ('Ph.D.', 'NNP'), ('student', 'NN'), ('.', '.')]\n"]}]},{"cell_type":"code","source":["# 한글 POS\n","from konlpy.tag import Okt # Open Korea Text\n","from konlpy.tag import Kkma # 꼬꼬마\n","# 이외: Mecab, Komoran, Hannanum"],"metadata":{"id":"4v11Qt4HzxLF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["okt = Okt()\n","kkma = Kkma()\n","\n","text = \"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"\n","\n","print(\"okt.morphs:\", okt.morphs(text)) # 형태소\n","print(\"okt.pos:\", okt.pos(text)) # 품사\n","print(\"okt.nouns\", okt.nouns(text)) # 명사만\n","\n","print(\"kkma.morphs\", kkma.morphs(text))\n","print(\"kkma.pos\", kkma.pos(text))\n","print(\"kkma.nouns\", kkma.nouns(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UcLekjj-0fEJ","executionInfo":{"status":"ok","timestamp":1735180720866,"user_tz":-540,"elapsed":13951,"user":{"displayName":"Sunki Min","userId":"10813170311541063515"}},"outputId":"da630801-979a-41d9-94fb-0090c203e23b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["okt.morphs: ['열심히', '코딩', '한', '당신', ',', '연휴', '에는', '여행', '을', '가봐요']\n","okt.pos: [('열심히', 'Adverb'), ('코딩', 'Noun'), ('한', 'Josa'), ('당신', 'Noun'), (',', 'Punctuation'), ('연휴', 'Noun'), ('에는', 'Josa'), ('여행', 'Noun'), ('을', 'Josa'), ('가봐요', 'Verb')]\n","okt.nouns ['코딩', '당신', '연휴', '여행']\n","kkma.morphs ['열심히', '코딩', '하', 'ㄴ', '당신', ',', '연휴', '에', '는', '여행', '을', '가보', '아요']\n","kkma.pos [('열심히', 'MAG'), ('코딩', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('당신', 'NP'), (',', 'SP'), ('연휴', 'NNG'), ('에', 'JKM'), ('는', 'JX'), ('여행', 'NNG'), ('을', 'JKO'), ('가보', 'VV'), ('아요', 'EFN')]\n","kkma.nouns ['코딩', '당신', '연휴', '여행']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"CWQtOW6M00UT"},"execution_count":null,"outputs":[]}]}